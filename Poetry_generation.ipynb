{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A small project about Poetry generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and prepare Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = pathlib.Path('data/poetry_data/')\n",
    "data= [ ]\n",
    "ite = 0\n",
    "for item in folder.iterdir():\n",
    "    if item.suffix == '.txt':\n",
    "        with open(item, 'r') as file:\n",
    "             lines = file.read().splitlines()\n",
    "             lines = list(filter(None, lines))\n",
    "             data.append(lines)\n",
    "\n",
    "        ite += 1\n",
    "        if ite==1:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform list of list to flat list\n",
    "data = [item1 for sublist in data for item1 in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = token.texts_to_sequences(data)\n",
    "vocab_size = len(token.word_counts) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4081"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset in order to predict the next word based at least on the previous word\n",
    "datalist = []\n",
    "for d in encoded_text:\n",
    "    if len(d)>1:\n",
    "        for i in range(2, len(d)):\n",
    "            datalist.append(d[:i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding to make the elements of datalist to have the same length\n",
    "max_length = 20\n",
    "sequences = pad_sequences(datalist, maxlen=max_length, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the last sequence as target\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "lenght_seq = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=lenght_seq)) \n",
    "model.add(LSTM(100, return_sequences=True)) #\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, 19, 50)            204050    \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 19, 100)           60400     \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 4081)              412181    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 767,131\n",
      "Trainable params: 767,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44382, 19)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 22:13:43.881174: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 22:13:44.211196: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 22:13:44.419684: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 22:13:44.915573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 22:13:45.274786: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1387/1387 [==============================] - 67s 45ms/step - loss: 6.0854 - accuracy: 0.0444\n",
      "Epoch 2/10\n",
      "1387/1387 [==============================] - 57s 41ms/step - loss: 5.6406 - accuracy: 0.0548\n",
      "Epoch 3/10\n",
      "1387/1387 [==============================] - 57s 41ms/step - loss: 5.3900 - accuracy: 0.0645\n",
      "Epoch 4/10\n",
      "1387/1387 [==============================] - 56s 41ms/step - loss: 5.1909 - accuracy: 0.0862\n",
      "Epoch 5/10\n",
      "1387/1387 [==============================] - 56s 41ms/step - loss: 5.0167 - accuracy: 0.1049\n",
      "Epoch 6/10\n",
      "1387/1387 [==============================] - 57s 41ms/step - loss: 4.8603 - accuracy: 0.1217\n",
      "Epoch 7/10\n",
      "1387/1387 [==============================] - 57s 41ms/step - loss: 4.7160 - accuracy: 0.1330\n",
      "Epoch 8/10\n",
      "1387/1387 [==============================] - 57s 41ms/step - loss: 4.5867 - accuracy: 0.1427\n",
      "Epoch 9/10\n",
      "1387/1387 [==============================] - 57s 41ms/step - loss: 4.4685 - accuracy: 0.1535\n",
      "Epoch 10/10\n",
      "1387/1387 [==============================] - 57s 41ms/step - loss: 4.3626 - accuracy: 0.1613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x322a2f100>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poetry Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words per verses\n",
    "poetry_length = 10\n",
    "\n",
    "def generate_poetry(init_text, nlines):\n",
    "    \"\"\"\n",
    "    Take an initial sentence and a number of verses\n",
    "    :params\n",
    "    init_text: Initial sentence\n",
    "    nlines: Number of lines\n",
    "    \"\"\"\n",
    "    for i in range(nlines):\n",
    "        text = []\n",
    "        for _ in range(poetry_length):\n",
    "            encoded = token.texts_to_sequences([init_text])\n",
    "            encoded = pad_sequences(encoded, maxlen=lenght_seq, padding='pre')\n",
    "\n",
    "            y_pred = np.argmax(model.predict(encoded, verbose=0), axis=-1)\n",
    "\n",
    "            predicted_word = \"\"\n",
    "            for word, index in token.word_index.items():\n",
    "                if index == y_pred:\n",
    "                    predicted_word = word\n",
    "                    break\n",
    "            init_text = init_text + ' ' + predicted_word\n",
    "            text.append(predicted_word)\n",
    "        init_text = text[-1]\n",
    "        text = ' '.join(text)\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 22:25:11.155236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 22:25:11.272953: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-05 22:25:11.434140: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 the name is prince the critics love u in\n",
      "the body u can be a beautiful of the critics\n",
      "love u in the world of a beautiful of the\n",
      "max u can be a new power generation u can\n",
      "u have 2 the max u can be a new\n"
     ]
    }
   ],
   "source": [
    "init_text = 'Let me go'\n",
    "generate_poetry(init_text, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
